import os
import subprocess
import csv
import multiprocessing
import sys
import shutil

# ==============================================================================
# 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå (PROJECT SETUP)
# ==============================================================================

# --- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô "‡∏Ñ‡∏ô‡∏á‡∏≤‡∏ô" ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏±‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô ---
# ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô SRA ID ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
NUM_PARALLEL_JOBS = 4

# --- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ‡∏´‡∏•‡∏±‡∏Å ---
BASE_DIR = os.getcwd()
OUTPUT_DIR = os.path.join(BASE_DIR, "analysis_output")
REF_DIR = os.path.join(BASE_DIR, "reference_data")
SAMPLE_SHEET_FILE = os.path.join(BASE_DIR, "samples.csv")
ADAPTER_FILE_PATH = os.path.join(REF_DIR, "TruSeq3-SE.fa") 

# --- ‡∏™‡∏£‡πâ‡∏≤‡∏á Directories ‡∏´‡∏•‡∏±‡∏Å (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå) ---
os.makedirs(OUTPUT_DIR, exist_ok=True)
for subdir in ["sra", "fastq_raw", "fastqc_raw", "fastq_trimmed"]:
    os.makedirs(os.path.join(OUTPUT_DIR, subdir), exist_ok=True)

# ==============================================================================
# 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á (HELPER FUNCTION)
# ==============================================================================

def execute_command(command_list, description, sra_id):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏° Logging"""
    log_prefix = f"[{sra_id}]"
    print(f"\n{log_prefix} üöÄ Starting: {description}...")
    print(f"{log_prefix}    Command: {' '.join(command_list)}")

    try:
        # ‡πÉ‡∏ä‡πâ capture_output=True ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ log ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å job ‡∏õ‡∏ô‡∏Å‡∏±‡∏ô‡∏°‡∏±‡πà‡∏ß‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å
        result = subprocess.run(command_list, check=True, text=True, 
                                executable=None, capture_output=True, timeout=3600) # 1 hour timeout
        print(f"{log_prefix} ‚úÖ Finished: {description} successfully.")
        return
    except subprocess.CalledProcessError as e:
        print(f"‚ùå ERROR in '{description}' for {sra_id}: {e}")
        # ‡∏û‡∏¥‡∏°‡∏û‡πå 5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Stderr ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Debug
        print(f"{log_prefix} STDERR: ...\n" + "\n".join(e.stderr.splitlines()[-5:]))
        raise e
    except subprocess.TimeoutExpired:
        print(f"‚ùå TIMEOUT: '{description}' for {sra_id} took too long.")
        raise Exception(f"Timeout on {sra_id}")

# ==============================================================================
# 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô "‡∏Ñ‡∏ô‡∏á‡∏≤‡∏ô" (WORKER FUNCTIONS) - ‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡∏Ç‡∏ô‡∏≤‡∏ô
# ==============================================================================

def run_qc_step(job_tuple):
    """
    ‡∏Ñ‡∏ô‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: Download, FastQC, Trimmomatic
    """
    sra_id, species_name = job_tuple
    try:
        # --- 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ---
        sra_path = os.path.join(OUTPUT_DIR, "sra")
        raw_fastq_path = os.path.join(OUTPUT_DIR, "fastq_raw")
        raw_fastqc_path = os.path.join(OUTPUT_DIR, "fastqc_raw")
        trimmed_fastq_path = os.path.join(OUTPUT_DIR, "fastq_trimmed")
        
        raw_fastq = os.path.join(raw_fastq_path, f"{sra_id}.fastq")
        trimmed_fastq = os.path.join(trimmed_fastq_path, f"{sra_id}_trimmed.fastq")

        # --- 2. Acquisition ---
        if not os.path.exists(raw_fastq):
            cmd_prefetch = ["prefetch", sra_id, "-O", sra_path]
            execute_command(cmd_prefetch, "Downloading", sra_id)
            sra_file = os.path.join(sra_path, sra_id, f"{sra_id}.sra")
            
            if not os.path.exists(sra_file):
                 sra_file = os.path.join(sra_path, f"{sra_id}.sra")
            
            cmd_dump = ["fastq-dump", "--outdir", raw_fastq_path, "--split-files", sra_file]
            execute_command(cmd_dump, "Converting to FASTQ", sra_id)
        
        # --- 3. QC Check ---
        cmd_fastqc = ["fastqc", raw_fastq, "-o", raw_fastqc_path]
        execute_command(cmd_fastqc, "Running FastQC", sra_id)

        # --- 4. QC Trim ---
        cmd_trim = [
            "trimmomatic", "SE",
            "-threads", "2",
            raw_fastq,
            trimmed_fastq,
            f"ILLUMINACLIP:{ADAPTER_FILE_PATH}:2:30:10",
            "LEADING:3",
            "TRAILING:3",
            "SLIDINGWINDOW:4:15",
            "MINLEN:36"
        ]
        execute_command(cmd_trim, "Trimming adapters", sra_id)
        
        return (sra_id, "QC_Success")
    except Exception as e:
        return (sra_id, f"QC_Failed: {e}")

def run_align_step(job_tuple):
    """
    ‡∏Ñ‡∏ô‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: STAR Alignment
    """
    sra_id, species_name = job_tuple
    try:
        # --- 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ---
        trimmed_fastq = os.path.join(OUTPUT_DIR, "fastq_trimmed", f"{sra_id}_trimmed.fastq")
        species_output_dir = os.path.join(OUTPUT_DIR, species_name)
        star_index_dir = os.path.join(REF_DIR, f"{species_name}_star_index")
        bam_path = os.path.join(species_output_dir, "bam_files")
        os.makedirs(bam_path, exist_ok=True)
        
        # --- 2. Alignment ---
        output_prefix = os.path.join(bam_path, f"{sra_id}_")
        cmd_star_align = [
            "STAR",
            "--runThreadN", "4",
            "--genomeDir", star_index_dir,
            "--readFilesIn", trimmed_fastq,
            "--outFileNamePrefix", output_prefix,
            "--outSAMtype", "BAM", "SortedByCoordinate"
        ]
        execute_command(cmd_star_align, "Aligning reads (STAR)", sra_id)
        
        return (sra_id, "Align_Success")
    except Exception as e:
        return (sra_id, f"Align_Failed: {e}")

def run_quantify_step(job_tuple):
    """
    ‡∏Ñ‡∏ô‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: htseq-count
    """
    sra_id, species_name = job_tuple
    try:
        # --- 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ---
        species_output_dir = os.path.join(OUTPUT_DIR, species_name)
        gff_file_path = os.path.join(REF_DIR, f"{species_name}.gff3")
        bam_path = os.path.join(species_output_dir, "bam_files")
        counts_path = os.path.join(species_output_dir, "counts_htseq")
        os.makedirs(counts_path, exist_ok=True)

        bam_file = os.path.join(bam_path, f"{sra_id}_Aligned.sortedByCoord.out.bam")
        count_file = os.path.join(counts_path, f"{sra_id}_counts.txt")

        # --- 2. Quantification ---
        cmd_htseq = [
            "htseq-count",
            "-f", "bam",
            "-r", "pos",
            "-s", "no",
            "--idattr=ID",
            bam_file,
            gff_file_path
        ]

        result = execute_command(cmd_htseq, "Counting reads (htseq-count)", sra_id)
        with open(count_file, 'w') as f:
            f.write(result.stdout)        
        return (sra_id, "Quant_Success")
    
    except Exception as e:
        return (sra_id, f"Quant_Failed: {e}")

# ==============================================================================
# 4. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô "‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£" (MANAGER FUNCTIONS)
# ==============================================================================

def build_star_indices(unique_species):
    """
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á STAR Index (‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ä‡∏ô‡∏Å‡∏±‡∏ô
    """
    print("\n" + "="*70)
    print("STEP 2: Building STAR Indices (Sequential)...")
    print("="*70)
    
    for species_name in unique_species:
        print(f"--- Checking Index for: {species_name} ---")
        genome_fasta_path = os.path.join(REF_DIR, f"{species_name}.fa")
        gff_file_path = os.path.join(REF_DIR, f"{species_name}.gff3")
        star_index_dir = os.path.join(REF_DIR, f"{species_name}_star_index")
        
        if not os.path.exists(genome_fasta_path) or not os.path.exists(gff_file_path):
            print(f"  [‚úó] WARNING: Missing {species_name}.fa or .gff3 in {REF_DIR}. Skipping index build.")
            continue
            
        if not os.path.exists(os.path.join(star_index_dir, "SA")):
            print(f"  [i] Index not found. Building...")
            os.makedirs(star_index_dir, exist_ok=True)
            cmd_star_index = [
                "STAR",
                "--runThreadN", str(NUM_PARALLEL_JOBS * 2),
                "--runMode", "genomeGenerate",
                "--genomeDir", star_index_dir,
                "--genomeFastaFiles", genome_fasta_path,
                "--sjdbGTFfile", gff_file_path,
                "--sjdbOverhang", "99"
            ]

            print(f"  üöÄ Starting: Building STAR index for {species_name}...")
            # ‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö List (shell=False ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
            subprocess.run(cmd_star_index, check=True, text=True, 
                           capture_output=True)
            print(f"  [‚úì] Finished: Index for {species_name} built successfully.")

            try:
                # ‡∏£‡∏±‡∏ô Index build ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô worker)
                print(f"  üöÄ Starting: Building STAR index for {species_name}...")
                subprocess.run(cmd_star_index, shell=True, check=True, text=True, 
                               executable='/bin/bash', capture_output=True)
                print(f"  [‚úì] Finished: Index for {species_name} built successfully.")
            except subprocess.CalledProcessError as e:
                print(f"  ‚ùå ERROR building index for {species_name}: {e.stderr}")
        else:
            print("  [‚úì] Index already exists.")

def main():
    
    # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° "‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏á‡∏≤‡∏ô" (Job List)
    print("="*70)
    print("Reading Job List from samples.csv...")
    print("="*70)
    
    jobs = []
    unique_species = set()
    try:
        with open(SAMPLE_SHEET_FILE, mode='r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                jobs.append((row['sra_id'], row['species_name']))
                unique_species.add(row['species_name'])
    except FileNotFoundError:
        print(f"‚ùå ERROR: Sample sheet not found at {SAMPLE_SHEET_FILE}")
        sys.exit(1)
        
    if not jobs:
        print("‚ùå ERROR: No jobs found in 'samples.csv'.")
        sys.exit(1)
        
    print(f"Found {len(jobs)} total SRA samples to process across {len(unique_species)} species.")
    
    # --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Pool ---
    pool = multiprocessing.Pool(processes=NUM_PARALLEL_JOBS)
    
    # 2. ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: QC (‡∏Ç‡∏ô‡∏≤‡∏ô)
    print("\n" + "="*70)
    print(f"STEP 1: Running QC (Parallel Jobs: {NUM_PARALLEL_JOBS})...")
    print("="*70)
    qc_results = pool.map(run_qc_step, jobs)
    
    # 3. ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Index (‡∏•‡∏≥‡∏î‡∏±‡∏ö)
    build_star_indices(unique_species)
    
    # 4. ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: Alignment (‡∏Ç‡∏ô‡∏≤‡∏ô)
    print("\n" + "="*70)
    print(f"STEP 3: Running Alignment (Parallel Jobs: {NUM_PARALLEL_JOBS})...")
    print("="*70)
    align_results = pool.map(run_align_step, jobs)

    # 5. ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: Quantification (‡∏Ç‡∏ô‡∏≤‡∏ô)
    print("\n" + "="*70)
    print(f"STEP 4: Running Quantification (Parallel Jobs: {NUM_PARALLEL_JOBS})...")
    print("="*70)
    quant_results = pool.map(run_quantify_step, jobs)
    
    # --- ‡∏õ‡∏¥‡∏î Pool ---
    pool.close()
    pool.join()
    
    # 6. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    print("\n" + "="*70)
    print("üéâüéâüéâ All Pipeline Stages Finished üéâüéâüéâ")
    print("="*70)
    
    # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á Dictionary ‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ---
    qc_status = dict(qc_results)
    align_status = dict(align_results)
    quant_status = dict(quant_results)
    
    all_sra_ids = [job[0] for job in jobs]
    failures = []
    success_count = 0
    
    print("--- Final Job Status Summary ---")
    print(f"{'SRA ID':<12} | {'QC':<12} | {'Alignment':<12} | {'Quantify':<12}")
    print("-" * 54)

    for sra_id in all_sra_ids:
        # ‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
        qc_stat = qc_status.get(sra_id, 'N/A')
        align_stat = align_status.get(sra_id, 'N/A')
        quant_stat = quant_status.get(sra_id, 'N/A')

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        is_qc_success = "Success" in qc_stat
        is_align_success = "Success" in align_stat
        is_quant_success = "Success" in quant_stat

        job_failed = False
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
        # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ 'elif' ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤ QC ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß, Alignment ‡πÅ‡∏•‡∏∞ Quantify ‡∏Å‡πá‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏£‡∏±‡∏ô (‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏ï‡∏≤‡∏°)
        if not is_qc_success:
            failures.append((sra_id, "QC", qc_stat))
            job_failed = True
        elif not is_align_success:
            failures.append((sra_id, "Alignment", align_stat))
            job_failed = True
        elif not is_quant_success:
            failures.append((sra_id, "Quantify", quant_stat))
            job_failed = True

        # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        if not job_failed:
            success_count += 1
            print(f"{sra_id:<12} | {'Success':<12} | {'Success':<12} | {'Success':<12}")
        else:
            qc_print = "Success" if is_qc_success else "FAILED"
            # ‡∏ñ‡πâ‡∏≤ QC ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß, Alignment ‡∏à‡∏∞‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏£‡∏±‡∏ô
            align_print = "Success" if is_align_success else ("FAILED" if is_qc_success else "Not Run")
            quant_print = "Success" if is_quant_success else ("FAILED" if is_align_success else "Not Run")
            print(f"{sra_id:<12} | {qc_print:<12} | {align_print:<12} | {quant_print:<12}")


    print("-" * 54)
    print(f"\nOverall Summary: {success_count} / {len(jobs)} samples processed successfully.")
    
    # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á SRA ID ‡∏ó‡∏µ‡πà‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
    if failures:
        print("\n--- üî• Failed Samples Details üî• ---")
        for sra_id, stage, status in failures:
            # ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° error ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á
            error_message = str(status).split('\n')[0] # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á error
            print(f"  SRA ID: {sra_id}")
            print(f"  Stage : {stage}")
            print(f"  Error : {error_message}...")
            print("-" * 30)

# --- ‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ---
if __name__ == "__main__":
    main()